{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765f4e77",
   "metadata": {},
   "source": [
    "# My Finanacial Analyzer Agent with the OpenAi client and ollam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f15f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://jarvita-agx:11434/v1',\n",
    "    api_key='ollama'\n",
    ")\n",
    "\n",
    "#  we create the ollama client to get the model info\n",
    "ollama_client = Client(\n",
    "  host='http://jarvita-agx:11434',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.list()\n",
    "for model in models['models']:\n",
    "    print(f\"-------{type(model)}-------\")\n",
    "    # model_info = client.show(model['model'])\n",
    "    for key, value in model:\n",
    "        print(f\"{key}: {value}\")\n",
    "    # print(model_info['capabilities'])\n",
    "    # for key, value in model:\n",
    "    #     print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b86d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=\"granite4:latest\"\n",
    "# model = \"gpt-oss:20b\"\n",
    "model = \"qwen3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ef8d6c",
   "metadata": {},
   "source": [
    "## Create an agent that likes to keep the conversation going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7484f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat(model=\"gemma3n:e2b\", messages=[\n",
    "  {'role': 'user', 'content': 'Why is the sky blue? use low reasoning and make it short'},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd8331f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunlight is made of all colors. When it enters the Earth's air, it bumps into tiny bits. Blue light is scattered more than other colors, so we see a blue sky! \n",
      "\n",
      "Short answer: Blue light scatters more! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2cabd01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in New York is 22°C. Let me know if you need more weather details!\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "def get_temperature(city: str) -> str:\n",
    "  \"\"\"Get the current temperature for a city\n",
    "  \n",
    "  Args:\n",
    "    city: The name of the city\n",
    "\n",
    "  Returns:\n",
    "    The current temperature for the city\n",
    "  \"\"\"\n",
    "  temperatures = {\n",
    "    \"New York\": \"22°C\",\n",
    "    \"London\": \"15°C\",\n",
    "    \"Tokyo\": \"18°C\",\n",
    "  }\n",
    "  return temperatures.get(city, \"Unknown\")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the temperature in New York?\"}]\n",
    "\n",
    "# pass functions directly as tools in the tools list or as a JSON schema\n",
    "response = client.chat(model=model, messages=messages, tools=[get_temperature], think=True)\n",
    "\n",
    "messages.append(response.message)\n",
    "if response.message.tool_calls:\n",
    "  # only recommended for models which only return a single tool call\n",
    "  call = response.message.tool_calls[0]\n",
    "  result = get_temperature(**call.function.arguments)\n",
    "  # add the tool result to the messages\n",
    "  messages.append({\"role\": \"tool\", \"tool_name\": call.function.name, \"content\": str(result)})\n",
    "\n",
    "  final_response = client.chat(model=model, messages=messages, tools=[get_temperature], think=True)\n",
    "  print(final_response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a469f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Canada' capital='Ottawa' languages=['English', 'French', 'Indigenous languages']\n"
     ]
    }
   ],
   "source": [
    "# Structured Output Class\n",
    "class Country(BaseModel):\n",
    "  name: str\n",
    "  capital: str\n",
    "  languages: list[str]\n",
    "\n",
    "response = client.chat(\n",
    "  model=model,\n",
    "  messages=[{'role': 'user', 'content': 'Tell me about Canada.'}],\n",
    "  format=Country.model_json_schema(),\n",
    ")\n",
    "\n",
    "country = Country.model_validate_json(response.message.content)\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ffc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that can answer questions and help with tasks.\n",
    "Please answer in bullet points and limit it to four bullet points with 2 sentances each.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-oss:20b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"\"}\n",
    "    ]\n",
    ")\n",
    " \n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await agent.run(\"How can reputation resolutsion help my company?\")\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481160f7",
   "metadata": {},
   "source": [
    "## Create an agent with memory with previous message memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await agent.run(\"What can reputation resolutsion do for me and give me 2 blog posts from them to read up on?\")\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = await agent.run(\"What company are we talking about?\", message_history=result.all_messages())\n",
    "print(result2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9015b8",
   "metadata": {},
   "source": [
    "### Longer Chat History Memory - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9716c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await agent.run(\"What is Data Science Dojo?\")\n",
    "print(result.output)\n",
    "memory.append(result.all_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))\n",
    "for i in result.all_messages():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await agent.run(\"Tell me about the company apple\")\n",
    "print(result.output)\n",
    "memory.append(result.all_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0060bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = await agent.run(\"What company are we talking about?\", message_history=result.all_messages())\n",
    "print(result2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85987192",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e2527",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await agent.run(\"What company are we talking about?\", message_history=memory)\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7abdee7",
   "metadata": {},
   "source": [
    "## Connect to Wevaite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "# WEAVIATE_KEY = os.getenv(\"WEAVIATE_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "\n",
    "# print(\"Weaviate URL:\", WEAVIATE_URL)\n",
    "# print(\"Weaviate API Key:\", WEAVIATE_KEY[:10])\n",
    "print(\"OpenAI API Key:\", OPENAI_API_KEY[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322d5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    # cluster_url=WEAVIATE_URL,\n",
    "    # auth_credentials=Auth.api_key(WEAVIATE_KEY),\n",
    "    headers = {\n",
    "        \"X-OpenAI-Api-Key\": OPENAI_API_KEY,\n",
    "        \"X-Cohere-Api-Key\": COHERE_API_KEY\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Client ready:\", client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our collection from before\n",
    "contracts = client.collections.use(\"ReputationresolutionsWebsite\")\n",
    "contracts_config = contracts.config.get()\n",
    "\n",
    "print(contracts_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f98bde",
   "metadata": {},
   "source": [
    "## Create a query enhancement agent\n",
    "\n",
    "This agent will take the users question and optimize it for the search to the vector database (Weaviate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996008a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "# Simple query optimizer and search agent\n",
    "query_enhancement_agent = Agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    instructions=\"You optimize queries for contract search, then search and return results.\",\n",
    ")\n",
    "\n",
    "async def search_(user_query):\n",
    "    # Optimize and search in one step\n",
    "    result = await query_enhancement_agent.run(f\"Optimize this query for search again a reputation management website: {user_query}\")\n",
    "    optimized_query = result.output\n",
    "\n",
    "    # Search the database\n",
    "    response = contracts.query.hybrid(query=optimized_query, limit=3)\n",
    "\n",
    "    # Show results\n",
    "    for i, contract in enumerate(response.objects):\n",
    "        print(f\"Page Title {i+1}: {contract.properties['page_title']}\")\n",
    "\n",
    "    return response.objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it\n",
    "results = await search_(\"How can reputation resolutsion help my company?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec13d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import Filter\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Get collection properties\n",
    "collection_config = contracts.config.get()\n",
    "properties = {prop.name: str(prop.data_type) for prop in collection_config.properties}\n",
    "\n",
    "# Smart filtering agent that creates filters automatically\n",
    "smart_filter_agent = Agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    instructions=f\"\"\"\n",
    "    You analyze queries and automatically create Weaviate filters.\n",
    "    Collection properties: {properties}\n",
    "    \n",
    "    Based on the user query, generate Python code that creates Filter objects.\n",
    "    Only return the filter code, nothing else.\n",
    "    \n",
    "    Examples:\n",
    "    - For \"Jane Doe contracts\": Filter.by_property(\"author\").equal(\"Jane Doe\")\n",
    "    - For \"recent employment contracts\": Filter.by_property(\"contract_type\").equal(\"employment contract\") & \n",
    "Filter.by_property(\"date\").greater_than(datetime(2023, 6, 1, tzinfo=timezone.utc))\n",
    "    - For \"short contracts\": Filter.by_property(\"contract_length\").less_than(2)\n",
    "    \n",
    "    If no filters needed, return: None\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "async def auto_filtered_search(user_query):\n",
    "    # Get filter code from agent\n",
    "    filter_result = await smart_filter_agent.run(f\"Create filters for: {user_query}\")\n",
    "    filter_code = filter_result.output.strip()\n",
    "\n",
    "    print(f\"Query: {user_query}\")\n",
    "    print(f\"Generated filter: {filter_code}\")\n",
    "\n",
    "    # Execute the filter code\n",
    "    query_filters = None\n",
    "    if filter_code != \"None\":\n",
    "        try:\n",
    "            query_filters = eval(filter_code)\n",
    "        except:\n",
    "            print(\"Filter creation failed, searching without filters\")\n",
    "\n",
    "    # Search with auto-generated filters\n",
    "    response = contracts.query.near_text(\n",
    "        query=user_query,\n",
    "        filters=query_filters,\n",
    "        limit=5\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFound {len(response.objects)} pages:\")\n",
    "    for i, contract in enumerate(response.objects):\n",
    "        print(f\"Document {i+1}: {contract.properties['page_title']}\")\n",
    "\n",
    "    return response.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09da147",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await auto_filtered_search(\"give me information about the use cases deloitte is talking about\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf60b3f8",
   "metadata": {},
   "source": [
    "# Put it all together\n",
    "\n",
    "We will do a query expansion and then run through our dynamic filter agentm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714dc9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.query import Filter\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def auto_filtered_search(user_query: str)-> str:\n",
    "    # Get collection properties\n",
    "    collection_config = contracts.config.get()\n",
    "    properties = {prop.name: str(prop.data_type) for prop in collection_config.properties}\n",
    "\n",
    "    # Smart filtering agent that creates filters automatically\n",
    "    smart_filter_agent = Agent(\n",
    "        model=\"openai:gpt-4o-mini\",\n",
    "        instructions=f\"\"\"\n",
    "        You analyze queries and automatically create Weaviate filters.\n",
    "        Collection properties: {properties}\n",
    "        \n",
    "        Based on the user query, generate Python code that creates Filter objects.\n",
    "        Only return the filter code, nothing else.\n",
    "        \n",
    "        Examples:\n",
    "        - For \"Jane Doe contracts\": Filter.by_property(\"author\").equal(\"Jane Doe\")\n",
    "        - For \"recent employment contracts\": Filter.by_property(\"contract_type\").equal(\"employment contract\") & \n",
    "    Filter.by_property(\"date\").greater_than(datetime(2023, 6, 1, tzinfo=timezone.utc))\n",
    "        - For \"short contracts\": Filter.by_property(\"contract_length\").less_than(2)\n",
    "        \n",
    "        If no filters needed, return: None\n",
    "        \"\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "    # Get filter code from agent\n",
    "    filter_result = smart_filter_agent.run(f\"Create filters for: {user_query}\")\n",
    "    filter_code = filter_result.output.strip()\n",
    "\n",
    "    print(f\"Query: {user_query}\")\n",
    "    print(f\"Generated filter: {filter_code}\")\n",
    "\n",
    "    # Execute the filter code\n",
    "    query_filters = None\n",
    "    if filter_code != \"None\":\n",
    "        try:\n",
    "            query_filters = eval(filter_code)\n",
    "        except:\n",
    "            print(\"Filter creation failed, searching without filters\")\n",
    "\n",
    "    # Search with auto-generated filters\n",
    "    response = contracts.query.near_text(\n",
    "        query=user_query,\n",
    "        filters=query_filters,\n",
    "        limit=5\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFound {len(response.objects)} contracts:\")\n",
    "    for i, contract in enumerate(response.objects):\n",
    "        print(f\"Document {i+1}: {contract.properties['document_title']} page {contract.properties['page']}\")\n",
    "\n",
    "    return response.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff65fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# planner_agent.py\n",
    "from pydantic_ai import Agent\n",
    "# from basic_tools import smart_filter_tool, query_enhancement_tool\n",
    "\n",
    "system = \"\"\"\n",
    "You are a planning agent.\n",
    "You can use two tools:\n",
    "1. smart_filter_tool(query) — filters or constrains a query.\n",
    "2. query_enhancement_tool(query) — expands or improves a query.\n",
    "\n",
    "Decide when to call each tool (or both, in sequence) to best improve a user query.\n",
    "Always output the final improved query as plain text.\n",
    "\"\"\"\n",
    "research_agent = Agent(\n",
    "    model=\"openai:gpt-4o\",\n",
    "    system_prompt=system,\n",
    "    tools=[auto_filtered_search],\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d405ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent_resul = await research_agent.run(f\"tell me about use cases on page 7 from deloitte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b55ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
